{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Environment & Imports\n",
        "\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "# Download required NLTK resources (including punkt_tab fix)\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # <-- Fix for new NLTK versions\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, confusion_matrix, classification_report)\n",
        "import joblib\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 1234\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9bStS_qT0jn",
        "outputId": "17d21be7-eebd-473d-87fd-5aadec13587e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load IMDB data\n",
        "VOCAB_SIZE = 20000  # Keep top 20k words\n",
        "(encoded_train_X, train_y), (encoded_test_X, test_y) = imdb.load_data(num_words=VOCAB_SIZE)\n",
        "\n",
        "# Build index -> word mapping\n",
        "raw_word_index = imdb.get_word_index()\n",
        "index_to_word = {idx + 3: w for w, idx in raw_word_index.items()}\n",
        "index_to_word[0] = \"<PAD>\"\n",
        "index_to_word[1] = \"<START>\"\n",
        "index_to_word[2] = \"<UNK>\"\n",
        "index_to_word[3] = \"<UNUSED>\"\n",
        "\n",
        "def decode_sequence(seq):\n",
        "    \"\"\"Convert list of word indices back into review text.\"\"\"\n",
        "    return \" \".join(index_to_word.get(i, \"?\") for i in seq)\n",
        "\n",
        "# Dataset info\n",
        "print(\"Train examples:\", len(encoded_train_X))\n",
        "print(\"Test examples:\", len(encoded_test_X))\n",
        "print(\"Sample decoded review:\\n\", decode_sequence(encoded_train_X[0])[:400])\n",
        "print(\"Label:\", train_y[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxSDNFgoT-Ww",
        "outputId": "4142a9cb-f5a0-491f-aa45-19f41a293e57"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train examples: 25000\n",
            "Test examples: 25000\n",
            "Sample decoded review:\n",
            " <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean and lemmatize text\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "punct_pattern = re.compile(f\"[{re.escape(string.punctuation)}]\")\n",
        "\n",
        "def clean_and_lemmatize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<[^>]+>\", \" \", text)  # remove HTML tags\n",
        "    text = punct_pattern.sub(\" \", text)   # remove punctuation\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Decode and clean\n",
        "X_train_text = [clean_and_lemmatize(decode_sequence(s)) for s in encoded_train_X]\n",
        "X_test_text  = [clean_and_lemmatize(decode_sequence(s)) for s in encoded_test_X]\n",
        "\n",
        "print(\"Processed sample:\", X_train_text[0][:200], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO_bwaXrUCMq",
        "outputId": "88648c49-84fe-40b8-ff68-2f03f7cbdd55"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed sample: film brilliant casting location scenery story direction everyone really suited part played could imagine robert amazing actor director father came scottish island loved fact real connection film witty ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Convert to TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=12000,\n",
        "    ngram_range=(1,2),\n",
        "    sublinear_tf=True,\n",
        "    max_df=0.95,\n",
        "    min_df=5\n",
        ")\n",
        "\n",
        "X_train_vec = tfidf_vectorizer.fit_transform(X_train_text)\n",
        "X_test_vec  = tfidf_vectorizer.transform(X_test_text)\n",
        "\n",
        "print(\"Train features:\", X_train_vec.shape)\n",
        "print(\"Test  features:\", X_test_vec.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHWf1kCLUSS8",
        "outputId": "6645716b-694d-4973-d21a-b92494e09853"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features: (25000, 12000)\n",
            "Test  features: (25000, 12000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train models and compare\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred),\n",
        "        \"recall\": recall_score(y_true, y_pred),\n",
        "        \"f1\": f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=400, C=1.0, random_state=RANDOM_STATE, solver=\"saga\"),\n",
        "    \"ComplementNB\": ComplementNB(),\n",
        "    \"LinearSVM(SGD)\": SGDClassifier(loss=\"hinge\", max_iter=1000, tol=1e-3, random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, clf in models.items():\n",
        "    clf.fit(X_train_vec, train_y)\n",
        "    preds = clf.predict(X_test_vec)\n",
        "    m = compute_metrics(test_y, preds)\n",
        "    print(f\"\\n{name} report:\\n\", classification_report(test_y, preds, digits=4))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(test_y, preds))\n",
        "    results.append((name, m[\"accuracy\"], m[\"precision\"], m[\"recall\"], m[\"f1\"]))\n",
        "\n",
        "# Results table\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "print(\"\\nSummary:\\n\", results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91JM8yJmUYDR",
        "outputId": "ca57e899-99f4-44f3-8db8-7a615e8b0c73"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LogisticRegression report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8927    0.8858    0.8893     12500\n",
            "           1     0.8867    0.8935    0.8901     12500\n",
            "\n",
            "    accuracy                         0.8897     25000\n",
            "   macro avg     0.8897    0.8897    0.8897     25000\n",
            "weighted avg     0.8897    0.8897    0.8897     25000\n",
            "\n",
            "Confusion matrix:\n",
            " [[11073  1427]\n",
            " [ 1331 11169]]\n",
            "\n",
            "ComplementNB report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8516    0.8698    0.8606     12500\n",
            "           1     0.8669    0.8484    0.8576     12500\n",
            "\n",
            "    accuracy                         0.8591     25000\n",
            "   macro avg     0.8592    0.8591    0.8591     25000\n",
            "weighted avg     0.8592    0.8591    0.8591     25000\n",
            "\n",
            "Confusion matrix:\n",
            " [[10872  1628]\n",
            " [ 1895 10605]]\n",
            "\n",
            "LinearSVM(SGD) report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8916    0.8857    0.8886     12500\n",
            "           1     0.8864    0.8923    0.8894     12500\n",
            "\n",
            "    accuracy                         0.8890     25000\n",
            "   macro avg     0.8890    0.8890    0.8890     25000\n",
            "weighted avg     0.8890    0.8890    0.8890     25000\n",
            "\n",
            "Confusion matrix:\n",
            " [[11071  1429]\n",
            " [ 1346 11154]]\n",
            "\n",
            "Summary:\n",
            "                 Model  Accuracy  Precision   Recall        F1\n",
            "0  LogisticRegression   0.88968   0.886710  0.89352  0.890102\n",
            "1        ComplementNB   0.85908   0.866917  0.84840  0.857559\n",
            "2      LinearSVM(SGD)   0.88900   0.886434  0.89232  0.889367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: CV on Logistic Regression\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "clf_for_cv = LogisticRegression(max_iter=400, C=1.0, solver=\"saga\", random_state=RANDOM_STATE)\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    clf_for_cv, X_train_vec, train_y, cv=cv,\n",
        "    scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(\"CV mean scores:\")\n",
        "print({k: np.mean(cv_results[k]) for k in cv_results if k.startswith(\"test_\")})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKJeODUOUcRe",
        "outputId": "d2fea078-39b9-43ff-df61-4fc05f0518c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV mean scores:\n",
            "{'test_accuracy': np.float64(0.8901199999999999), 'test_precision': np.float64(0.8799977847852617), 'test_recall': np.float64(0.9034400000000001), 'test_f1': np.float64(0.8915616199747932)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Pipeline + parameter tuning\n",
        "pipe = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(sublinear_tf=True)),\n",
        "    (\"clf\", LogisticRegression(max_iter=400, solver=\"saga\", random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"tfidf__max_features\": [5000, 10000],\n",
        "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
        "    \"clf__C\": [0.5, 1.0, 2.0]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train_text, train_y)\n",
        "\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Best CV accuracy:\", grid.best_score_)\n",
        "\n",
        "best_pipeline = grid.best_estimator_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJSlhamUfbH",
        "outputId": "c2234ed9-2f0b-44d2-f3cb-891177d55642"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Best params: {'clf__C': 2.0, 'tfidf__max_features': 10000, 'tfidf__ngram_range': (1, 2)}\n",
            "Best CV accuracy: 0.8894799132498058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate tuned pipeline\n",
        "test_preds = best_pipeline.predict(X_test_text)\n",
        "print(\"Classification report:\\n\", classification_report(test_y, test_preds, digits=4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(test_y, test_preds))\n",
        "print(\"Final metrics:\", compute_metrics(test_y, test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9m9rZaLUjLN",
        "outputId": "d4895d25-9bbf-4bed-b001-2ff5da8d0e0e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8897    0.8858    0.8877     12500\n",
            "           1     0.8863    0.8902    0.8883     12500\n",
            "\n",
            "    accuracy                         0.8880     25000\n",
            "   macro avg     0.8880    0.8880    0.8880     25000\n",
            "weighted avg     0.8880    0.8880    0.8880     25000\n",
            "\n",
            "Confusion matrix:\n",
            " [[11072  1428]\n",
            " [ 1372 11128]]\n",
            "Final metrics: {'accuracy': 0.888, 'precision': 0.8862695125836254, 'recall': 0.89024, 'f1': 0.888250319284802}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8A: sample from test set\n",
        "sample_indices = [10, 50, 200, 1000, 2500]\n",
        "for i in sample_indices:\n",
        "    print(\"\\n--- Test Review\", i, \"---\")\n",
        "    print(\"Raw:\", decode_sequence(encoded_test_X[i])[:300], \"...\")\n",
        "    pred = best_pipeline.predict([X_test_text[i]])[0]\n",
        "    print(\"Predicted:\", \"Positive\" if pred == 1 else \"Negative\")\n",
        "    print(\"Actual:   \", \"Positive\" if test_y[i] == 1 else \"Negative\")\n",
        "\n",
        "# Step 8B: custom reviews\n",
        "custom_reviews = [\n",
        "    \"I loved every minute of this film. The acting was brilliant.\",\n",
        "    \"Boring, slow, and unoriginal. I nearly fell asleep.\",\n",
        "    \"A solid movie with a few great moments, but overall average.\",\n",
        "    \"One of the best films I've seen in years — highly recommended!\",\n",
        "    \"Bad script and worse acting. Don't waste your time.\"\n",
        "]\n",
        "processed_custom = [clean_and_lemmatize(r) for r in custom_reviews]\n",
        "preds_custom = best_pipeline.predict(processed_custom)\n",
        "for r, p in zip(custom_reviews, preds_custom):\n",
        "    print(\"\\nReview:\", r)\n",
        "    print(\"Prediction:\", \"Positive\" if p == 1 else \"Negative\")\n"
      ],
      "metadata": {
        "id": "nJo1mZvtVKsV",
        "outputId": "192d22b9-92fc-4974-e23e-e96e9390eb37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test Review 10 ---\n",
            "Raw: <START> inspired by hitchcock's strangers on a train concept of two men swapping murders in exchange for getting rid of the two people messing up their lives throw <UNK> from the train is an original and very inventive comedy take on the idea it's a credit to danny devito that he both wrote and star ...\n",
            "Predicted: Positive\n",
            "Actual:    Positive\n",
            "\n",
            "--- Test Review 50 ---\n",
            "Raw: <START> first of i should point out that i used to love <UNK> the <UNK> as a child and i really enjoyed the movie even though i am in my 20's br br but this movie was so bad i was ashamed to have been a fan in my youth br br ok ok i know this is a movie for kids and isn't aimed at people like me any ...\n",
            "Predicted: Negative\n",
            "Actual:    Negative\n",
            "\n",
            "--- Test Review 200 ---\n",
            "Raw: <START> don't be fooled this isn't yet another tired example of the girls from outer space pretending to be the french ski team come to earth to collect as much sperm as possible genre though the synopsis may suggest otherwise this movie is a gem an absolute jewel that has <UNK> my life from the mom ...\n",
            "Predicted: Positive\n",
            "Actual:    Positive\n",
            "\n",
            "--- Test Review 1000 ---\n",
            "Raw: <START> whoa this is one of the worst movies i have ever seen the packaging for the film is better than the film itself my girlfriend and i watched it this past weekend and we only continued to watch it in the hopes that it would get better it didn't br br the picture quality is poor it looks like i ...\n",
            "Predicted: Negative\n",
            "Actual:    Negative\n",
            "\n",
            "--- Test Review 2500 ---\n",
            "Raw: <START> ok so i gotta start this review by saying i was really expecting to see this flick for months i use to watch its trailer and think it looked really cool little did i know that the only cool thing about this cliché driven turd was precisely its trailer br br at the cinema i watched the first  ...\n",
            "Predicted: Negative\n",
            "Actual:    Negative\n",
            "\n",
            "Review: I loved every minute of this film. The acting was brilliant.\n",
            "Prediction: Positive\n",
            "\n",
            "Review: Boring, slow, and unoriginal. I nearly fell asleep.\n",
            "Prediction: Negative\n",
            "\n",
            "Review: A solid movie with a few great moments, but overall average.\n",
            "Prediction: Positive\n",
            "\n",
            "Review: One of the best films I've seen in years — highly recommended!\n",
            "Prediction: Positive\n",
            "\n",
            "Review: Bad script and worse acting. Don't waste your time.\n",
            "Prediction: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Save best pipeline for future use\n",
        "joblib.dump(best_pipeline, \"imdb_best_pipeline.pkl\")\n",
        "print(\"Saved pipeline as imdb_best_pipeline.pkl\")\n"
      ],
      "metadata": {
        "id": "UKa2r-1TVMVQ",
        "outputId": "c5987104-f4f2-4a8d-8ba2-3e4bd2c42766",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pipeline as imdb_best_pipeline.pkl\n"
          ]
        }
      ]
    }
  ]
}